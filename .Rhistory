LRAUC1
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
LRpredicted_data <- data.frame(Probs = LRprobTest, Actual_Value=LRactualTest,Predicted_Value = LRpredTest )  #Create data frame with prob and predictions
LRpredicted_data <- LRpredicted_data[order(LRpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
LRpredicted_data$Rank <- 1:nrow(LRpredicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=LRpredicted_data, aes(x=Rank, y=Probs)) +
geom_point(aes(color = LRpredicted_data$Actual_Value)) + xlab("Index") + ylab("Heart Disease Prediction")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236, sysBP = 102.0, diaBP = 71, BMI = 100, heartRate = 100, glucose = 200 )
# terminal nodes
# age
# glucose
# diaBP
# BMI
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
## Performance measures
# Simplicity =  coefficients
# Accuracy = 0.8552321 0r 0.86
# AUC = 0.7011 0r 0.7
write.csv(dataset,file = "./output/LR_BO_CHD.csv",row.names = FALSE)
dataset <- read.csv("./output/LR_BO_CHD.csv",header = TRUE)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras","readr","dplyr","party","partykit")
#install.packages(installus)
#Authors BH$OTB
library(rpart)
library(readr)
library(caTools)
library(dplyr)
library(party)
library(partykit)
library(rpart.plot)
library(rpart)
library(pROC)
### Step 1 - Load data and get summaries
dataset <- read.csv("./data/framingham.csv") %>% # read in the data
mutate(TenYearCHD = factor(TenYearCHD)) # target variable dependent variable to factor
## Replacing null values with the mean value
dataset[is.na(dataset$education),"education"] <- as.integer(mean(dataset$education,na.rm = T))
dataset[is.na(dataset$cigsPerDay),"cigsPerDay"] <- as.integer(mean(dataset$cigsPerDay, na.rm = T))
dataset[is.na(dataset$BPMeds),"BPMeds"] <- as.integer(mean(dataset$BPMeds,na.rm = T))
dataset[is.na(dataset$totChol),"totChol"] <- as.integer(mean(dataset$totChol,na.rm = T))
dataset[is.na(dataset$BMI),"BMI"] <- as.integer(mean(dataset$BMI,na.rm = T))
dataset[is.na(dataset$heartRate),"heartRate"] <- as.integer(mean(dataset$heartRate,na.rm = T))
dataset[is.na(dataset$glucose),"glucose"] <- as.integer(mean(dataset$glucose,na.rm = T))
## Remove null values
dataset <- dataset[!is.na(dataset$education),]
dataset <- dataset[!is.na(dataset$cigsPerDay),]
dataset <- dataset[!is.na(dataset$BPMeds),]
dataset <- dataset[!is.na(dataset$totChol),]
dataset <- dataset[!is.na(dataset$BMI),]
dataset <- dataset[!is.na(dataset$heartRate),]
dataset <- dataset[!is.na(dataset$glucose),]
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
### Step 2 - Split data into training and testing data
set.seed(1)
DTDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
DTtrainData <- dataset[DTDataset,]
dim(DTtrainData)
DTtestData <- dataset[!DTDataset,]
dim(DTtestData)
### Step 3 - Fit a Decision Tree using training data
#DTmodel <- rpart(TenYearCHD ~ .,method="class", data=DTtrainData, parms = list (split ="information gain"), control = rpart.control(minsplit = 10, maxdepth = 5))
#DTmodel <- rpart(TenYearCHD ~ .,method="class", data=DTtrainData, parms = list (split ="gini"), control = rpart.control(minsplit = 15, maxdepth = 5))
DTmodel <- rpart(TenYearCHD ~ .,method="class", data=DTtrainData)
# Fitting the model
#rpart.plot(DTmodel, type=3, extra = 101, fallen.leaves = F, cex = 0.8) ##try extra with 2,8,4, 101
rpart.plot(DTmodel)
summary(DTmodel) # detailed summary of splits
DTmodel #prints the rules
###Step 4 - Use the fitted model to do predictions for the test data
DTpredTest <- predict(DTmodel, DTtestData, type="class")
DTprobTest <- predict(DTmodel, DTtestData, type="prob")
DTactualTest <- DTtestData$TenYearCHD
### Step 5 - Create Confusion Matrix and compute the misclassification error
DTt <- table(predictions= DTpredTest, actual = DTactualTest)
DTt # Confusion matrix
DTaccuracy <- sum(diag(DTt))/sum(DTt)
DTaccuracy
## Visualization of probabilities
hist(DTprobTest[,2], breaks = 100)
### ROC and Area Under the Curve
DTROC <- roc(DTactualTest, DTprobTest[,2])
plot(DTROC, col="blue")
DTAUC <- auc(DTROC)
DTAUC
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
DTpredicted_data <- data.frame(Probs = DTprobTest, Actual_Value= DTactualTest ,Predicted_Value = DTpredTest )  #Create data frame with prob and predictions
DTpredicted_data <- DTpredicted_data[order(DTpredicted_data$Probs.1, decreasing=TRUE),] # Sort on Probabilities
DTpredicted_data$Rank <- 1:nrow(DTpredicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=DTpredicted_data, aes(x=Rank, y=Probs.1)) +
geom_point(aes(color = DTpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of getting Cardiovascular Diseases")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
DTnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236, sysBP = 102.0, diaBP = 71, BMI = 100, heartRate = 100, glucose = 200 )
# terminal nodes
# age
# glucose
# diaBP
# BMI
DTpredProbability <-predict(DTmodel, DTnewData, type='prob')
DTpredProbability
#
## Performance measures -
#
#set.seed(1), gini
# Simplicity = 15 leaves
# Accuracy = 0.8394965 0r 0.84
# AUC = 0.6621 0r 0.66
#
#set.seed(1), information
# Simplicity = 10 leaves
# Accuracy = 0.8394965 0r 0.84
# AUC = 0.6621 0r 0.66
#
#set.seed(1), blank
# Accuracy = 0.8371361 0r 0.84
# AUC = 0.6627 0r 0.66
#
### Step 7 - EXAMINING STABILITY - Creating Decile Plots for Class 1 or 0 Sort
#
#-----Create empty df-------
DTdecile<- data.frame(matrix(ncol=4,nrow = 0))
colnames(DTdecile)<- c("Decile","per_correct_preds","No_correct_Preds","cum_preds")
#-----Initialize variables
DTnum_of_deciles = 10
DTObs_per_decile <- nrow(DTpredicted_data)/DTnum_of_deciles
DTdecile_count = 1
DTstart = 1
DTstop = (DTstart-1) + DTObs_per_decile
DTprev_cum_pred <- 0
DTx = 0
#-----Loop through DF and create deciles
while (DTx < nrow(DTpredicted_data)) {
DTsubset <- DTpredicted_data[c(DTstart:DTstop),]
DTcorrect_count <- ifelse(DTsubset$Actual_Value == DTsubset$Predicted_Value, 1, 0)
DTno_correct_Preds <- sum(DTcorrect_count, na.rm = TRUE)
DTper_correct_Preds <- (DTno_correct_Preds / DTObs_per_decile) * 100
DTcum_preds <- DTno_correct_Preds+DTprev_cum_pred
DTaddRow <- data.frame("Decile" = DTdecile_count, "per_correct_preds" = DTper_correct_Preds, "No_correct_Preds" = DTno_correct_Preds, "cum_preds" = DTcum_preds)
DTdecile <- rbind(DTdecile,DTaddRow)
DTprev_cum_pred <- DTprev_cum_pred+DTno_correct_Preds
DTstart <- DTstop + 1
DTstop = (DTstart - 1) + DTObs_per_decile
DTx <- DTx+DTObs_per_decile
DTdecile_count <- DTdecile_count + 1
}
#------Stability plot (correct preds per decile)
plot(DTdecile$Decile,DTdecile$per_correct_preds,type = "l",xlab = "Decile",ylab = "Percentage of correct predictions",main="Stability Plot for Class 1")
write.csv(dataset,file = "./output/DT_BO_CHD.csv",row.names = FALSE)
dataset <- read.csv("./output/DT_BO_CHD.csv",header = TRUE)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("caTools")
#install.packages(installus)
library(caTools)
### Step 1 - Load data and get summaries
dataset <- read.csv("./data/framingham.csv")
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
## Replacing null values with the mean value
dataset[is.na(dataset$education),"education"] <- as.integer(mean(dataset$education,na.rm = T))
dataset[is.na(dataset$cigsPerDay),"cigsPerDay"] <- as.integer(mean(dataset$cigsPerDay, na.rm = T))
dataset[is.na(dataset$BPMeds),"BPMeds"] <- as.integer(mean(dataset$BPMeds,na.rm = T))
dataset[is.na(dataset$totChol),"totChol"] <- as.integer(mean(dataset$totChol,na.rm = T))
dataset[is.na(dataset$BMI),"BMI"] <- as.integer(mean(dataset$BMI,na.rm = T))
dataset[is.na(dataset$heartRate),"heartRate"] <- as.integer(mean(dataset$heartRate,na.rm = T))
dataset[is.na(dataset$glucose),"glucose"] <- as.integer(mean(dataset$glucose,na.rm = T))
## Remove null values
dataset <- dataset[!is.na(dataset$education),]
dataset <- dataset[!is.na(dataset$cigsPerDay),]
dataset <- dataset[!is.na(dataset$BPMeds),]
dataset <- dataset[!is.na(dataset$totChol),]
dataset <- dataset[!is.na(dataset$BMI),]
dataset <- dataset[!is.na(dataset$heartRate),]
dataset <- dataset[!is.na(dataset$glucose),]
# target variable dependent variable to factor
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
## Rechecking for null values
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
dim(dataset)
head(dataset, 10)
barplot(table(dataset$TenYearCHD), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$age)
## CHD value counts
table(dataset$TenYearCHD)
### Step 2 - Split data into training and testing data
set.seed(20)
LRDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
LRtrainData <- dataset[LRDataset,]
dim(LRtrainData)
LRtestData <- dataset[!LRDataset,]
dim(LRtestData)
### Step 3 - Fit a Logistic Model using training data
#Target Variable = TenYearCHD, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
LRModel <- glm(TenYearCHD ~ ., data=LRtrainData, family=binomial(link="logit"))
summary(LRModel)
# log likelihood
logLik(LRModel)
# R-squared
LRll.null <- LRModel$null.deviance/-2
LRll.proposed <- LRModel$deviance/-2
LRr_sq <- (LRll.null - LRll.proposed)/LRll.null
LRr_sq
#P value
LRp_value <- 1 - pchisq(2*(LRll.proposed - LRll.null), df = (length(LRModel$coefficients)-1))
LRp_value
###Step 4 - Use the fitted model to do predictions for the test data
#LRprobTest- Probability for Test data, LRpredTest - Predictions for Test data, actual - Actual Value in test data
LRprobTest=predict(LRModel, LRtestData, type = "response")  # Predict probabilities
LRprobTest
#Recode probability to classification
LRpredVal <- ifelse(LRprobTest >= 0.5, 1, 0)
LRpredTest <- factor(LRpredVal, levels = c(0,1))
#LRprobTest [0:45]
#LRpredTest[0:45]
LRprobTest
LRpredTest
LRactualTest <-LRtestData$TenYearCHD
#LRactualTest[0:5]
LRactualTest
### Step 5 - Create Confusion Matrix and compute the misclassification error
LRt <- table(predictions=LRpredTest, actual = LRactualTest)
LRt # Confusion matrix
hist(LRt)
LRaccuracy <- sum(diag(LRt))/sum(LRt)
LRaccuracy
### ROC and Area Under the Curve
LRROC1 <- roc(LRactualTest, LRprobTest)
plot(LRROC1, col="blue")
LRAUC1 <- auc(LRROC1)
LRAUC1
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
LRpredicted_data <- data.frame(Probs = LRprobTest, Actual_Value=LRactualTest,Predicted_Value = LRpredTest )  #Create data frame with prob and predictions
LRpredicted_data <- LRpredicted_data[order(LRpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
LRpredicted_data$Rank <- 1:nrow(LRpredicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=LRpredicted_data, aes(x=Rank, y=Probs)) +
geom_point(aes(color = LRpredicted_data$Actual_Value)) + xlab("Index") + ylab("Heart Disease Prediction")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236, sysBP = 102.0, diaBP = 71, BMI = 100, heartRate = 100, glucose = 200 )
# terminal nodes
# age
# glucose
# diaBP
# BMI
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
## Performance measures
# Simplicity =  coefficients
# Accuracy = 0.8552321 0r 0.86
# AUC = 0.7011 0r 0.7
write.csv(dataset,file = "./output/LR_BO_CHD.csv",row.names = FALSE)
dataset <- read.csv("./output/LR_BO_CHD.csv",header = TRUE)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("caTools")
#install.packages(installus)
library(caTools)
### Step 1 - Load data and get summaries
dataset <- read.csv("./data/framingham.csv")
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
## Replacing null values with the mean value
dataset[is.na(dataset$education),"education"] <- as.integer(mean(dataset$education,na.rm = T))
dataset[is.na(dataset$cigsPerDay),"cigsPerDay"] <- as.integer(mean(dataset$cigsPerDay, na.rm = T))
dataset[is.na(dataset$BPMeds),"BPMeds"] <- as.integer(mean(dataset$BPMeds,na.rm = T))
dataset[is.na(dataset$totChol),"totChol"] <- as.integer(mean(dataset$totChol,na.rm = T))
dataset[is.na(dataset$BMI),"BMI"] <- as.integer(mean(dataset$BMI,na.rm = T))
dataset[is.na(dataset$heartRate),"heartRate"] <- as.integer(mean(dataset$heartRate,na.rm = T))
dataset[is.na(dataset$glucose),"glucose"] <- as.integer(mean(dataset$glucose,na.rm = T))
## Remove null values
dataset <- dataset[!is.na(dataset$education),]
dataset <- dataset[!is.na(dataset$cigsPerDay),]
dataset <- dataset[!is.na(dataset$BPMeds),]
dataset <- dataset[!is.na(dataset$totChol),]
dataset <- dataset[!is.na(dataset$BMI),]
dataset <- dataset[!is.na(dataset$heartRate),]
dataset <- dataset[!is.na(dataset$glucose),]
# target variable dependent variable to factor
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
## Rechecking for null values
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
dim(dataset)
head(dataset, 10)
barplot(table(dataset$TenYearCHD), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$age)
## CHD value counts
table(dataset$TenYearCHD)
write.csv(dataset,file = "./output/NN_BO_CHD.csv",row.names = FALSE)
dataset <- read.csv("./output/NN_BO_CHD.csv",header = TRUE)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("caTools")
#install.packages(installus)
library(caTools)
### Step 1 - Load data and get summaries
dataset <- read.csv("./data/framingham.csv")
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
## Replacing null values with the mean value
dataset[is.na(dataset$education),"education"] <- as.integer(mean(dataset$education,na.rm = T))
dataset[is.na(dataset$cigsPerDay),"cigsPerDay"] <- as.integer(mean(dataset$cigsPerDay, na.rm = T))
dataset[is.na(dataset$BPMeds),"BPMeds"] <- as.integer(mean(dataset$BPMeds,na.rm = T))
dataset[is.na(dataset$totChol),"totChol"] <- as.integer(mean(dataset$totChol,na.rm = T))
dataset[is.na(dataset$BMI),"BMI"] <- as.integer(mean(dataset$BMI,na.rm = T))
dataset[is.na(dataset$heartRate),"heartRate"] <- as.integer(mean(dataset$heartRate,na.rm = T))
dataset[is.na(dataset$glucose),"glucose"] <- as.integer(mean(dataset$glucose,na.rm = T))
## Remove null values
dataset <- dataset[!is.na(dataset$education),]
dataset <- dataset[!is.na(dataset$cigsPerDay),]
dataset <- dataset[!is.na(dataset$BPMeds),]
dataset <- dataset[!is.na(dataset$totChol),]
dataset <- dataset[!is.na(dataset$BMI),]
dataset <- dataset[!is.na(dataset$heartRate),]
dataset <- dataset[!is.na(dataset$glucose),]
# target variable dependent variable to factor
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
## Rechecking for null values
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
dim(dataset)
head(dataset, 10)
barplot(table(dataset$TenYearCHD), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$age)
## CHD value counts
table(dataset$TenYearCHD)
### Step 2 - Split data into training and testing data
set.seed(7)
NNnewDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
NNtrainData <- dataset[NNnewDataset,]
NNtestData <- dataset[!NNnewDataset,]
write.csv(dataset,file = "./output/NN_BO_CHD.csv",row.names = FALSE)
dataset <- read.csv("./output/NN_BO_CHD.csv",header = TRUE)
## trainX contains first 8 columns of trainData
NNtrainX <- NNtrainData[, 1:8]
summary(NNtrainX)
## trainY contains last column of trainData
NNtrainY <- as.data.frame(NNtrainData$TenYearCHD)
colnames(NNtrainY) <- c("Class") #Modify variable name to Class
View(NNtrainY)
View(NNtrainX)
### Step 2 - Split data into training and testing data
set.seed(7)
NNnewDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
NNtrainData <- dataset[NNnewDataset,]
NNtestData <- dataset[!NNnewDataset,]
## trainX contains all columns of trainData
NNtrainX <- NNtrainData
summary(NNtrainX)
## trainY contains last column of trainData
NNtrainY <- as.data.frame(NNtrainData$TenYearCHD)
colnames(NNtrainY) <- c("Class") #Modify variable name to Class
## testX contains all columns of testData
NNtestX <- NNtestData
summary(NNtestX)
View(NNtrainX)
## NNtestY contains last column of testData
NNtestY <- as.data.frame(NNtestData$TenYearCHD)
colnames(NNtestY) <- c("Class") #Modify variable name to Class
View(NNtestY)
View(NNtestX)
View(NNtestY)
View(NNtestX)
View(NNtestY)
View(NNtrainX)
View(NNtrainY)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
library(caTools)
library(pROC)
library(keras)
### Step 1 - Load data and get summaries
dataset <- read.csv("./data/framingham.csv")
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
## Replacing null values with the mean value
dataset[is.na(dataset$education),"education"] <- as.integer(mean(dataset$education,na.rm = T))
dataset[is.na(dataset$cigsPerDay),"cigsPerDay"] <- as.integer(mean(dataset$cigsPerDay, na.rm = T))
dataset[is.na(dataset$BPMeds),"BPMeds"] <- as.integer(mean(dataset$BPMeds,na.rm = T))
dataset[is.na(dataset$totChol),"totChol"] <- as.integer(mean(dataset$totChol,na.rm = T))
dataset[is.na(dataset$BMI),"BMI"] <- as.integer(mean(dataset$BMI,na.rm = T))
dataset[is.na(dataset$heartRate),"heartRate"] <- as.integer(mean(dataset$heartRate,na.rm = T))
dataset[is.na(dataset$glucose),"glucose"] <- as.integer(mean(dataset$glucose,na.rm = T))
## Remove null values
dataset <- dataset[!is.na(dataset$education),]
dataset <- dataset[!is.na(dataset$cigsPerDay),]
dataset <- dataset[!is.na(dataset$BPMeds),]
dataset <- dataset[!is.na(dataset$totChol),]
dataset <- dataset[!is.na(dataset$BMI),]
dataset <- dataset[!is.na(dataset$heartRate),]
dataset <- dataset[!is.na(dataset$glucose),]
# target variable dependent variable to factor
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
## Rechecking for null values
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
dim(dataset)
head(dataset, 10)
barplot(table(dataset$TenYearCHD), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$age)
## CHD value counts
table(dataset$TenYearCHD)
### Step 2 - Split data into training and testing data
set.seed(7)
NNnewDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
NNtrainData <- dataset[NNnewDataset,]
NNtestData <- dataset[!NNnewDataset,]
## NNtrainX contains first 15 columns of NNtrainData
NNtrainX <- NNtrainData[, 1:15]
summary(NNtrainX)
## NNtrainY contains last column of NNtrainData
NNtrainY <- as.data.frame(NNtrainData$TenYearCHD)
colnames(NNtrainY) <- c("Class") #Modify variable name to Class
## testX contains first 15 columns of NNtestData
NNtestX <- NNtestData[, 1:15]
summary(NNtestX)
## NNtestY contains last column of NNtestData
NNtestY <- as.data.frame(NNtestData$TenYearCHD)
colnames(NNtestY) <- c("Class") #Modify variable name to Class
View(NNtestX)
View(NNtestY)
## NNnewTrain -> Change training (X & Y) data into correct format to build model - convert X and Y to vectors and matrices
NNnewTrainY <- as.vector(NNtrainY)
NNnewTrainY <- as.matrix(NNnewTrainY)
View(NNnewTrainY)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
library(caTools)
library(pROC)
library(keras)
### Step 1 - Load data and get summaries
dataset <- read.csv("./data/framingham.csv")
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
## Replacing null values with the mean value
dataset[is.na(dataset$education),"education"] <- as.integer(mean(dataset$education,na.rm = T))
dataset[is.na(dataset$cigsPerDay),"cigsPerDay"] <- as.integer(mean(dataset$cigsPerDay, na.rm = T))
dataset[is.na(dataset$BPMeds),"BPMeds"] <- as.integer(mean(dataset$BPMeds,na.rm = T))
dataset[is.na(dataset$totChol),"totChol"] <- as.integer(mean(dataset$totChol,na.rm = T))
dataset[is.na(dataset$BMI),"BMI"] <- as.integer(mean(dataset$BMI,na.rm = T))
dataset[is.na(dataset$heartRate),"heartRate"] <- as.integer(mean(dataset$heartRate,na.rm = T))
dataset[is.na(dataset$glucose),"glucose"] <- as.integer(mean(dataset$glucose,na.rm = T))
## Remove null values
dataset <- dataset[!is.na(dataset$education),]
dataset <- dataset[!is.na(dataset$cigsPerDay),]
dataset <- dataset[!is.na(dataset$BPMeds),]
dataset <- dataset[!is.na(dataset$totChol),]
dataset <- dataset[!is.na(dataset$BMI),]
dataset <- dataset[!is.na(dataset$heartRate),]
dataset <- dataset[!is.na(dataset$glucose),]
# target variable dependent variable to factor
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
## Rechecking for null values
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
dim(dataset)
head(dataset, 10)
barplot(table(dataset$TenYearCHD), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$age)
## CHD value counts
table(dataset$TenYearCHD)
### Step 2 - Split data into training and testing data
set.seed(7)
NNnewDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
NNtrainData <- dataset[NNnewDataset,]
NNtestData <- dataset[!NNnewDataset,]
## NNtrainX contains first 15 columns of NNtrainData
NNtrainX <- NNtrainData[, 1:15]
summary(NNtrainX)
## NNtrainY contains last column of NNtrainData
NNtrainY <- as.data.frame(NNtrainData$TenYearCHD)
colnames(NNtrainY) <- c("Class") #Modify variable name to Class
## testX contains first 15 columns of NNtestData
NNtestX <- NNtestData[, 1:15]
summary(NNtestX)
## NNtestY contains last column of NNtestData
NNtestY <- as.data.frame(NNtestData$TenYearCHD)
colnames(NNtestY) <- c("Class") #Modify variable name to Class
## NNnewTrain -> Change training (X & Y) data into correct format to build model - convert X and Y to vectors and matrices
NNnewTrainY <- as.vector(NNtrainY)
NNnewTrainY <- as.matrix(NNnewTrainY)
View(NNnewTrainY)
