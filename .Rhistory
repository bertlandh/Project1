# Fitting the model
rpart.plot(DTmodel1, type=3, extra = 101, fallen.leaves = F, cex = 0.8,box.palette="blue")
rpart.plot(DTmodel1,box.palette="blue")
rpart.plot(DTmodel2,box.palette="blue")
summary(DTmodel1) # detailed summary of splits
DTmodel1 #prints the rules
DTHLpredTest <- predict(DTmodel1, tst, type="class")
DTHLprobTest <- predict(DTmodel1, tst, type="prob")
DTHLactualTest <- tst$y
View(as.data.frame(DTHLactualTest))
### Step 5 - Create Confusion Matrix and compute the misclassification error
DTHLt <- table(predictions= DTHLpredTest, actual = DTHLactualTest)
DTHLt # Confusion matrix
DTHLaccuracy <- sum(diag(DTHLt))/sum(DTHLt)
DTHLaccuracy
## Visualization of probabilities
hist(DTHLprobTest[,2], breaks = 100)
## ROC and Area Under the Curve
DTHLROC <- roc(DTHLactualTest, DTHLprobTest[,2])
plot(DTHLROC, col="blue")
DTHLAUC <- auc(DTHLROC)
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
DTHLpredicted_data <- data.frame(Probs = DTHLprobTest, Actual_Value= DTHLactualTest ,Predicted_Value = DTHLpredTest )  #Create data frame with prob and predictions
View(DTHLpredicted_data)
DTHLpredicted_data <- DTHLpredicted_data[order(DTHLpredicted_data$Probs.1, decreasing=TRUE),] # Sort on Probabilities
#DTHLpredicted_data <- DTHLpredicted_data[order(DTHLpredicted_data$Probs.1, decreasing=TRUE),] # Sort on Probabilities
DTHLpredicted_data$Rank <- 1:nrow(DTHLpredicted_data) # Add a new variable rank
View(DTHLpredicted_data)
DTHLpredicted_data <- DTHLpredicted_data[order(DTHLpredicted_data$Probs.High, decreasing=TRUE),] # Sort on Probabilities
DTHLpredicted_data$Rank <- 1:nrow(DTHLpredicted_data) # Add a new variable rank
ggplot(data=DTpredicted_data, aes(x=Rank, y=Probs.1)) +
geom_point(aes(color = DTHLpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of Heating Load")
ggplot(data=DTHLpredicted_data, aes(x=Rank, y=Probs.1)) +
geom_point(aes(color = DTHLpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of Heating Load")
ggplot(data=DTHLpredicted_data, aes(x=Rank, y=Probs.High)) +
geom_point(aes(color = DTHLpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of Heating Load")
DTHLpredProbability <-predict(DTHLmodel, DTHLnewData, type='prob')
View(trn)
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
DTnewData <- data.frame(X1=1,X2=2,X3=3,X4=4,X5=5,X6=6,X8=8)
DTHLpredProbability <-predict(DTmodel1, DTHLnewData, type='prob')
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
DTHLnewData <- data.frame(X1=1,X2=2,X3=3,X4=4,X5=5,X6=6,X8=8)
DTHLpredProbability <-predict(DTmodel1, DTHLnewData, type='prob')
DTHLpredProbability
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
DTHLnewData <- data.frame(X1=8,X2=2.5,X3=4.857143,X4=2,X5=7,X6=4,X8=)
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
DTHLnewData <- data.frame(X1=8,X2=2.5,X3=4.857143,X4=2,X5=7,X6=4,X8=4)
DTHLpredProbability <-predict(DTmodel1, DTHLnewData, type='prob')
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
DTHLnewData <- data.frame(X1=8,X2=2.5,X3=4.857143,X4=2,X5=7,X6=4,X8=4)
DTHLnewData$X5 <- as.factor(DTHLnewData$X5)
DTHLnewData$X6 <- as.factor(DTHLnewData$X6)
DTHLnewData$X8 <- as.factor(DTHLnewData$X8)
DTHLpredProbability <-predict(DTmodel1, DTHLnewData, type='prob')
DTHLpredProbability
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
#DTHLnewData <- data.frame(X1=8,X2=2.5,X3=4.857143,X4=2,X5=7,X6=4,X8=4) # High
DTHLnewData <- data.frame(X1=2.75,X2=7.75,X3=3.571429,X4=10,X5=3.5,X6=2,X8=2) # Low
DTHLnewData$X5 <- as.factor(DTHLnewData$X5)
DTHLnewData$X6 <- as.factor(DTHLnewData$X6)
DTHLnewData$X8 <- as.factor(DTHLnewData$X8)
DTHLpredProbability <-predict(DTmodel1, DTHLnewData, type='prob')
DTHLpredProbability
## Step 7 - EXAMINING STABILITY - Creating Decile Plots for Class 1 or 0 Sort
#
#-----Create empty df-------
DTdecile<- data.frame(matrix(ncol=4,nrow = 0))
colnames(DTdecile)<- c("Decile","per_correct_preds","No_correct_Preds","cum_preds")
#-----Initialize variables
DTnum_of_deciles = 10
DTObs_per_decile <- nrow(DTpredicted_data)/DTnum_of_deciles
DTObs_per_decile <- nrow(DTHLpredicted_data)/DTnum_of_deciles
DTdecile_count = 1
DTstart = 1
DTstop = (DTstart-1) + DTObs_per_decile
DTprev_cum_pred <- 0
DTx = 0
#-----Loop through DF and create deciles
while (DTx < nrow(DTpredicted_data)) {
DTsubset <- DTpredicted_data[c(DTstart:DTstop),]
DTcorrect_count <- ifelse(DTsubset$Actual_Value == DTsubset$Predicted_Value, 1, 0)
DTno_correct_Preds <- sum(DTcorrect_count, na.rm = TRUE)
DTper_correct_Preds <- (DTno_correct_Preds / DTObs_per_decile) * 100
DTcum_preds <- DTno_correct_Preds+DTprev_cum_pred
DTaddRow <- data.frame("Decile" = DTdecile_count, "per_correct_preds" = DTper_correct_Preds, "No_correct_Preds" = DTno_correct_Preds, "cum_preds" = DTcum_preds)
DTdecile <- rbind(DTdecile,DTaddRow)
DTprev_cum_pred <- DTprev_cum_pred+DTno_correct_Preds
DTstart <- DTstop + 1
DTstop = (DTstart - 1) + DTObs_per_decile
DTx <- DTx+DTObs_per_decile
DTdecile_count <- DTdecile_count + 1
}
#-----Loop through DF and create deciles
while (DTx < nrow(DTHLpredicted_data)) {
DTsubset <- DTHLpredicted_data[c(DTstart:DTstop),]
DTcorrect_count <- ifelse(DTsubset$Actual_Value == DTsubset$Predicted_Value, 1, 0)
DTno_correct_Preds <- sum(DTcorrect_count, na.rm = TRUE)
DTper_correct_Preds <- (DTno_correct_Preds / DTObs_per_decile) * 100
DTcum_preds <- DTno_correct_Preds+DTprev_cum_pred
DTaddRow <- data.frame("Decile" = DTdecile_count, "per_correct_preds" = DTper_correct_Preds, "No_correct_Preds" = DTno_correct_Preds, "cum_preds" = DTcum_preds)
DTdecile <- rbind(DTdecile,DTaddRow)
DTprev_cum_pred <- DTprev_cum_pred+DTno_correct_Preds
DTstart <- DTstop + 1
DTstop = (DTstart - 1) + DTObs_per_decile
DTx <- DTx+DTObs_per_decile
DTdecile_count <- DTdecile_count + 1
}
#------Stability plot (correct preds per decile)
plot(DTdecile$Decile,DTdecile$per_correct_preds,type = "l",xlab = "Decile",ylab = "Percentage of correct predictions",main="Stability Plot for Class 1")
DTdecile_count
# Clear data
rm(list = ls())  # Removes all objects from the environment
# Clear packages
p_unload(all)    # Remove all contributed packages
# Clear plots
graphics.off()   # Clears plots, closes all graphics devices
# Clear console
cat("\014")      # Mimics ctrl+L
# Install and/or load packages with pacman
pacman::p_load(  # Use p_load function from pacman
caret,         # Train/test functions
e1071,         # Machine learning functions
magrittr,      # Pipes
pacman,        # Load/unload packages
rattle,        # Pretty plot for decision trees
rio,           # Import/export data
tidyverse,     # So many reasons
rpart,         # Fit a rpart model
rpart.plot,    # Plot an rpart model
pROC           # Tools for visualizing
)
# Set random seed to reproduce the results
set.seed(1)
# Import training data `trn`
trn <- import("data/ENB2012_trn.rds")
# Import testing data `tst`
tst <- import("data/ENB2012_tst.rds")
#############my code
### Step 3 - Fit a Decision Tree using training data
DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="information gain"), control = rpart.control(minsplit = 10, maxdepth = 5))
# Fitting the model
rpart.plot(DTmodel1, type=3, extra = 101, fallen.leaves = F, cex = 0.8,box.palette="blue")
#rpart.plot(DTmodel1,box.palette="blue")
rpart.plot(DTmodel2,box.palette="blue")
rpart.plot(DTmodel1,box.palette="blue")
summary(DTmodel1) # detailed summary of splits
DTmodel1 #prints the rules
DTHLpredTest <- predict(DTmodel1, tst, type="class")
DTHLprobTest <- predict(DTmodel1, tst, type="prob")
DTHLactualTest <- tst$y
### Step 5 - Create Confusion Matrix and compute the misclassification error
DTHLt <- table(predictions= DTHLpredTest, actual = DTHLactualTest)
DTHLt # Confusion matrix
DTHLaccuracy <- sum(diag(DTHLt))/sum(DTHLt)
DTHLaccuracy
## Visualization of probabilities
hist(DTHLprobTest[,2], breaks = 100)
## ROC and Area Under the Curve
DTHLROC <- roc(DTHLactualTest, DTHLprobTest[,2])
plot(DTHLROC, col="blue")
DTHLAUC <- auc(DTHLROC)
DTHLAUC
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
DTHLpredicted_data <- data.frame(Probs = DTHLprobTest, Actual_Value= DTHLactualTest ,Predicted_Value = DTHLpredTest )  #Create data frame with prob and predictions
DTHLpredicted_data <- DTHLpredicted_data[order(DTHLpredicted_data$Probs.High, decreasing=TRUE),] # Sort on Probabilities
DTHLpredicted_data$Rank <- 1:nrow(DTHLpredicted_data) # Add a new variable rank
ggplot(data=DTHLpredicted_data, aes(x=Rank, y=Probs.High)) +
geom_point(aes(color = DTHLpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of Heating Load")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
#DTHLnewData <- data.frame(X1=8,X2=2.5,X3=4.857143,X4=2,X5=7,X6=4,X8=4) # High
DTHLnewData <- data.frame(X1=2.75,X2=7.75,X3=3.571429,X4=10,X5=3.5,X6=2,X8=2) # Low
DTHLnewData$X5 <- as.factor(DTHLnewData$X5)
DTHLnewData$X6 <- as.factor(DTHLnewData$X6)
DTHLnewData$X8 <- as.factor(DTHLnewData$X8)
DTHLpredProbability <-predict(DTmodel1, DTHLnewData, type='prob')
DTHLpredProbability
## Step 7 - EXAMINING STABILITY - Creating Decile Plots for Class High or Low Sort
#
#-----Create empty df-------
DTdecile<- data.frame(matrix(ncol=4,nrow = 0))
colnames(DTdecile)<- c("Decile","per_correct_preds","No_correct_Preds","cum_preds")
#-----Initialize variables
DTnum_of_deciles = 10
DTObs_per_decile <- nrow(DTHLpredicted_data)/DTnum_of_deciles
DTdecile_count = 1
DTstart = 1
DTstop = (DTstart-1) + DTObs_per_decile
DTprev_cum_pred <- 0
DTx = 0
#-----Loop through DF and create deciles
while (DTx < nrow(DTHLpredicted_data)) {
DTsubset <- DTHLpredicted_data[c(DTstart:DTstop),]
DTcorrect_count <- ifelse(DTsubset$Actual_Value == DTsubset$Predicted_Value, 1, 0)
DTno_correct_Preds <- sum(DTcorrect_count, na.rm = TRUE)
DTper_correct_Preds <- (DTno_correct_Preds / DTObs_per_decile) * 100
DTcum_preds <- DTno_correct_Preds+DTprev_cum_pred
DTaddRow <- data.frame("Decile" = DTdecile_count, "per_correct_preds" = DTper_correct_Preds, "No_correct_Preds" = DTno_correct_Preds, "cum_preds" = DTcum_preds)
DTdecile <- rbind(DTdecile,DTaddRow)
DTprev_cum_pred <- DTprev_cum_pred+DTno_correct_Preds
DTstart <- DTstop + 1
DTstop = (DTstart - 1) + DTObs_per_decile
DTx <- DTx+DTObs_per_decile
DTdecile_count <- DTdecile_count + 1
}
#------Stability plot (correct preds per decile)
plot(DTdecile$Decile,DTdecile$per_correct_preds,type = "l",xlab = "Decile",ylab = "Percentage of correct predictions",main="Stability Plot for Class 1")
# Clear data
rm(list = ls())  # Removes all objects from the environment
# Clear packages
p_unload(all)    # Remove all contributed packages
# Clear plots
graphics.off()   # Clears plots, closes all graphics devices
# Clear console
cat("\014")      # Mimics ctrl+L
# Install and/or load packages with pacman
pacman::p_load(  # Use p_load function from pacman
caret,         # Train/test functions
e1071,         # Machine learning functions
magrittr,      # Pipes
pacman,        # Load/unload packages
rattle,        # Pretty plot for decision trees
rio,           # Import/export data
tidyverse,     # So many reasons
rpart,         # Fit a rpart model
rpart.plot,    # Plot an rpart model
pROC           # Tools for visualizing
)
# Set random seed to reproduce the results
set.seed(1)
# Import training data `trn`
trn <- import("data/ENB2012_trn.rds")
# Import testing data `tst`
tst <- import("data/ENB2012_tst.rds")
### Step 3 - Fit a Decision Tree using training data
DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="information gain"), control = rpart.control(minsplit = 10, maxdepth = 5))
# Fitting the model
rpart.plot(DTmodel1, type=3, extra = 101, fallen.leaves = F, cex = 0.8,box.palette="blue")
rpart.plot(DTmodel1,box.palette="blue")
summary(DTmodel1) # detailed summary of splits
DTmodel1 #prints the rules
DTHLpredTest <- predict(DTmodel1, tst, type="class")
DTHLprobTest <- predict(DTmodel1, tst, type="prob")
DTHLactualTest <- tst$y
### Step 5 - Create Confusion Matrix and compute the misclassification error
DTHLt <- table(predictions= DTHLpredTest, actual = DTHLactualTest)
DTHLt # Confusion matrix
DTHLaccuracy <- sum(diag(DTHLt))/sum(DTHLt)
DTHLaccuracy
## Visualization of probabilities
hist(DTHLprobTest[,2], breaks = 100)
## ROC and Area Under the Curve
DTHLROC <- roc(DTHLactualTest, DTHLprobTest[,2])
plot(DTHLROC, col="blue")
DTHLAUC <- auc(DTHLROC)
DTHLAUC
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
DTHLpredicted_data <- data.frame(Probs = DTHLprobTest, Actual_Value= DTHLactualTest ,Predicted_Value = DTHLpredTest )  #Create data frame with prob and predictions
DTHLpredicted_data <- DTHLpredicted_data[order(DTHLpredicted_data$Probs.High, decreasing=TRUE),] # Sort on Probabilities
DTHLpredicted_data$Rank <- 1:nrow(DTHLpredicted_data) # Add a new variable rank
ggplot(data=DTHLpredicted_data, aes(x=Rank, y=Probs.High)) +
geom_point(aes(color = DTHLpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of Heating Load")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
#DTHLnewData <- data.frame(X1=8,X2=2.5,X3=4.857143,X4=2,X5=7,X6=4,X8=4) # High
DTHLnewData <- data.frame(X1=2.75,X2=7.75,X3=3.571429,X4=10,X5=3.5,X6=2,X8=2) # Low
DTHLnewData$X5 <- as.factor(DTHLnewData$X5)
DTHLnewData$X6 <- as.factor(DTHLnewData$X6)
DTHLnewData$X8 <- as.factor(DTHLnewData$X8)
DTHLpredProbability <-predict(DTmodel1, DTHLnewData, type='prob')
DTHLpredProbability
## Step 7 - EXAMINING STABILITY - Creating Decile Plots for Class High or Low Sort
#
#-----Create empty df-------
DTdecile<- data.frame(matrix(ncol=4,nrow = 0))
colnames(DTdecile)<- c("Decile","per_correct_preds","No_correct_Preds","cum_preds")
#-----Initialize variables
DTnum_of_deciles = 10
DTObs_per_decile <- nrow(DTHLpredicted_data)/DTnum_of_deciles
DTdecile_count = 1
DTstart = 1
DTstop = (DTstart-1) + DTObs_per_decile
DTprev_cum_pred <- 0
DTx = 0
#-----Loop through DF and create deciles
while (DTx < nrow(DTHLpredicted_data)) {
DTsubset <- DTHLpredicted_data[c(DTstart:DTstop),]
DTcorrect_count <- ifelse(DTsubset$Actual_Value == DTsubset$Predicted_Value, 1, 0)
DTno_correct_Preds <- sum(DTcorrect_count, na.rm = TRUE)
DTper_correct_Preds <- (DTno_correct_Preds / DTObs_per_decile) * 100
DTcum_preds <- DTno_correct_Preds+DTprev_cum_pred
DTaddRow <- data.frame("Decile" = DTdecile_count, "per_correct_preds" = DTper_correct_Preds, "No_correct_Preds" = DTno_correct_Preds, "cum_preds" = DTcum_preds)
DTdecile <- rbind(DTdecile,DTaddRow)
DTprev_cum_pred <- DTprev_cum_pred+DTno_correct_Preds
DTstart <- DTstop + 1
DTstop = (DTstart - 1) + DTObs_per_decile
DTx <- DTx+DTObs_per_decile
DTdecile_count <- DTdecile_count + 1
}
#------Stability plot (correct preds per decile)
plot(DTdecile$Decile,DTdecile$per_correct_preds,type = "l",xlab = "Decile",ylab = "Percentage of correct predictions",main="Stability Plot for Class 1")
# Clear data
rm(list = ls())  # Removes all objects from the environment
# Clear packages
p_unload(all)    # Remove all contributed packages
# Clear plots
graphics.off()   # Clears plots, closes all graphics devices
# Clear console
cat("\014")      # Mimics ctrl+L
# Install and/or load packages with pacman
pacman::p_load(  # Use p_load function from pacman
caret,         # Train/test functions
e1071,         # Machine learning functions
magrittr,      # Pipes
pacman,        # Load/unload packages
rattle,        # Pretty plot for decision trees
rio,           # Import/export data
tidyverse,     # So many reasons
rpart,         # Fit a rpart model
rpart.plot,    # Plot an rpart model
pROC           # Tools for visualizing
)
# Set random seed to reproduce the results
set.seed(1)
# Import training data `trn`
trn <- import("data/ENB2012_trn.rds")
# Import testing data `tst`
tst <- import("data/ENB2012_tst.rds")
# Fit a Decision Tree using training data  ####################################
#DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="information gain"), control = rpart.control(minsplit = 10, maxdepth = 5))
DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="gini"), control = rpart.control(minsplit = 15, maxdepth = 5))
# Fitting the model
rpart.plot(DTmodel1, type=3, extra = 101, fallen.leaves = F, cex = 0.8,box.palette="blue")
rpart.plot(DTmodel1,box.palette="blue")
summary(DTmodel1) # detailed summary of splits
DTmodel1 #prints the rules
# Use the fitted model to do predictions for the test data  ####################################
DTHLpredTest <- predict(DTmodel1, tst, type="class")
DTHLprobTest <- predict(DTmodel1, tst, type="prob")
DTHLactualTest <- tst$y
# Create Confusion Matrix and compute the misclassification error  ####################################
DTHLt <- table(predictions= DTHLpredTest, actual = DTHLactualTest)
DTHLt # Confusion matrix
DTHLaccuracy <- sum(diag(DTHLt))/sum(DTHLt)
DTHLaccuracy
## Visualization of probabilities
hist(DTHLprobTest[,2], breaks = 100)
## ROC and Area Under the Curve
DTHLROC <- roc(DTHLactualTest, DTHLprobTest[,2])
plot(DTHLROC, col="blue")
DTHLAUC <- auc(DTHLROC)
DTHLAUC
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
DTHLpredicted_data <- data.frame(Probs = DTHLprobTest, Actual_Value= DTHLactualTest ,Predicted_Value = DTHLpredTest )  #Create data frame with prob and predictions
## ROC and Area Under the Curve
DTHLROC <- roc(DTHLactualTest, DTHLprobTest[,2])
plot(DTHLROC, col="blue")
DTHLAUC <- auc(DTHLROC)
DTHLAUC
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
DTHLpredicted_data <- data.frame(Probs = DTHLprobTest, Actual_Value= DTHLactualTest ,Predicted_Value = DTHLpredTest )  #Create data frame with prob and predictions
DTHLpredicted_data <- DTHLpredicted_data[order(DTHLpredicted_data$Probs.High, decreasing=TRUE),] # Sort on Probabilities
DTHLpredicted_data$Rank <- 1:nrow(DTHLpredicted_data) # Add a new variable rank
ggplot(data=DTHLpredicted_data, aes(x=Rank, y=Probs.High)) +
geom_point(aes(color = DTHLpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of Heating Load")
# Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records  ####################################
#DTHLnewData <- data.frame(X1=8,X2=2.5,X3=4.857143,X4=2,X5=7,X6=4,X8=4) # High
DTHLnewData <- data.frame(X1=2.75,X2=7.75,X3=3.571429,X4=10,X5=3.5,X6=2,X8=2) # Low
DTHLnewData$X5 <- as.factor(DTHLnewData$X5)
DTHLnewData$X6 <- as.factor(DTHLnewData$X6)
DTHLnewData$X8 <- as.factor(DTHLnewData$X8)
DTHLpredProbability <-predict(DTmodel1, DTHLnewData, type='prob')
DTHLpredProbability
# EXAMINING STABILITY - Creating Decile Plots for Class High or Low Sort  ####################################
#
#-----Create empty df
DTdecile<- data.frame(matrix(ncol=4,nrow = 0))
colnames(DTdecile)<- c("Decile","per_correct_preds","No_correct_Preds","cum_preds")
#-----Initialize variables
DTnum_of_deciles = 10
DTObs_per_decile <- nrow(DTHLpredicted_data)/DTnum_of_deciles
DTdecile_count = 1
DTstart = 1
DTstop = (DTstart-1) + DTObs_per_decile
DTprev_cum_pred <- 0
DTx = 0
#-----Loop through DF and create deciles
while (DTx < nrow(DTHLpredicted_data)) {
DTsubset <- DTHLpredicted_data[c(DTstart:DTstop),]
DTcorrect_count <- ifelse(DTsubset$Actual_Value == DTsubset$Predicted_Value, 1, 0)
DTno_correct_Preds <- sum(DTcorrect_count, na.rm = TRUE)
DTper_correct_Preds <- (DTno_correct_Preds / DTObs_per_decile) * 100
DTcum_preds <- DTno_correct_Preds+DTprev_cum_pred
DTaddRow <- data.frame("Decile" = DTdecile_count, "per_correct_preds" = DTper_correct_Preds, "No_correct_Preds" = DTno_correct_Preds, "cum_preds" = DTcum_preds)
DTdecile <- rbind(DTdecile,DTaddRow)
DTprev_cum_pred <- DTprev_cum_pred+DTno_correct_Preds
DTstart <- DTstop + 1
DTstop = (DTstart - 1) + DTObs_per_decile
DTx <- DTx+DTObs_per_decile
DTdecile_count <- DTdecile_count + 1
}
#------Stability plot (correct preds per decile)
plot(DTdecile$Decile,DTdecile$per_correct_preds,type = "l",xlab = "Decile",ylab = "Percentage of correct predictions",main="Stability Plot for Class 1")
library(caTools)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
DiabetesDataset <- read.csv(file.choose())
summary(DiabetesDataset)
str(DiabetesDataset)
DiabetesDataset$Class <- as.factor(DiabetesDataset$Class)
str(DiabetesDataset)
dim(DiabetesDataset)
head(DiabetesDataset, 10)  #tail prints from back
is.na(DiabetesDataset)
cor(DiabetesDataset[,-9])  #[,-9] to exclude the 9th Class variable
pairs(DiabetesDataset[,-9])
table(DiabetesDataset$Class)
barplot(table(DiabetesDataset$Class), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(DiabetesDataset$Age)
### Step 2 - Split data into training and testing data
set.seed(20)
newDataset <-sample.split(Y=DiabetesDataset$Class, SplitRatio = 0.7)
trainData <- DiabetesDataset[newDataset,]
dim(trainData)
testData <- DiabetesDataset[!newDataset,]
dim(testData)
### Step 3 - Fit a Logistic Model using training data
rModel <- glm(Class ~ ., data=trainData, family=binomial(link="logit"))
#Target Variable = Class, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
summary(rModel)
# log likelihood
logLik(rModel)
# R-squared
ll.null <- rModel$null.deviance/-2
ll.proposed <- rModel$deviance/-2
r_sq <- (ll.null - ll.proposed)/ll.null
r_sq
#P value
p_value <- 1 - pchisq(2*(ll.proposed - ll.null), df = (length(rModel$coefficients)-1))
p_value
probTest=predict(rModel, testData, type = "response")  # Predict probabilities
#Recode probability to classification
predVal <- ifelse(probTest >= 0.5, 1, 0)
predTest <- factor(predVal, levels = c(0,1))
probTest [0:5]
predTest[0:5]
actualTest <-testData$Class
actualTest[0:5]
t <- table(predictions=predTest, actual = actualTest)
t # Confusion matrix
accuracy <- sum(diag(t))/sum(t)
accuracy
ROC1 <- roc(actualTest, probTest)
plot(ROC1, col="blue")
AUC1 <- auc(ROC1)
AUC1
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
predicted_data <- data.frame(Probs = probTest, Actual_Value=actualTest,Predicted_Value = predTest )  #Create data frame with prob and predictions
predicted_data <- predicted_data[order(predicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
predicted_data$Rank <- 1:nrow(predicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=predicted_data, aes(x=Rank, y=Probs)) +
geom_point(aes(color = predicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of getting Diabetes")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
newData <- data.frame(Nbr_Preg = 4 , Glucose_test = 100, Triceps_SF=40,BP =95, S_insulin = 150, BMI= 30,Diabetes_fn = 0.54,Age = 50 )
predProbability <-predict(rModel, newData, type='response')
predProbability
erformnce measures -
erformnce measures -
# Simplicity = 7 coefficients
erformnce measures -
# Simplicity = 7 coefficients
# Accuracy = 0.7695652 or 0.77
# Install and/or load packages with pacman
pacman::p_load(  # Use p_load function from pacman
caret,         # Train/test functions
e1071,         # Machine learning functions
magrittr,      # Pipes
pacman,        # Load/unload packages
rattle,        # Pretty plot for decision trees
rio,           # Import/export data
tidyverse,     # So many reasons
rpart,         # Fit a rpart model
rpart.plot,    # Plot an rpart model
pROC           # Tools for visualizing
)
# Set random seed to reproduce the results
set.seed(1)
# Import training data `trn`
trn <- import("data/ENB2012_trn.rds")
# Import testing data `tst`
tst <- import("data/ENB2012_tst.rds")
# DECISON TREES  ####################################
## Fit a Decision Tree using training data  ####################################
#DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="information gain"), control = rpart.control(minsplit = 10, maxdepth = 5))
DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="gini"), control = rpart.control(minsplit = 15, maxdepth = 5))
## Fitting the model   ####################################
rpart.plot(DTmodel1, type=3, extra = 101, fallen.leaves = F, cex = 0.8,box.palette="blue")
rpart.plot(DTmodel1,box.palette="blue")
summary(DTmodel1) # detailed summary of splits
# DECISON TREES  ####################################
## Fit a Decision Tree using training data  ####################################
#DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="information gain"), control = rpart.control(minsplit = 10, maxdepth = 5))
DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="gini"), control = rpart.control(minsplit = 15, maxdepth = 5))
## Fitting the model   ####################################
rpart.plot(DTmodel1, type=3, extra = 101, fallen.leaves = F, cex = 0.8,box.palette="blue")
# DECISON TREES  ####################################
## Fit a Decision Tree using training data  ####################################
DTmodel1 <- rpart(y ~ .,method="class", data=trn, parms = list (split ="information gain"), control = rpart.control(minsplit = 10, maxdepth = 5))
## Fitting the model   ####################################
rpart.plot(DTmodel1, type=3, extra = 101, fallen.leaves = F, cex = 0.8,box.palette="blue")
rpart.plot(DTmodel1,box.palette="blue")
