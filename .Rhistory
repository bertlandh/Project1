#DTnewData$prevalentHyp <- as.factor(DTnewData$prevalentHyp)
#DTnewData$diabetes <- as.factor(DTnewData$diabetes)
##
#
DTpredProbability <-predict(DTmodel, DTnewData, type='prob')
DTpredProbability
#
## Performance measures -
#
#set.seed(1), gini
# Simplicity = 15 leaves
# Accuracy = 0.8394965 0r 0.84
# AUC = 0.6621 0r 0.66
#
#set.seed(1), information
# Simplicity = 10 leaves
# Accuracy = 0.8394965 0r 0.84
# AUC = 0.6621 0r 0.66
#
#set.seed(1), blank
# Accuracy = 0.8371361 0r 0.84
# AUC = 0.6627 0r 0.66
#
### Step 7 - EXAMINING STABILITY - Creating Decile Plots for Class 1 or 0 Sort
#
#-----Create empty df-------
DTdecile<- data.frame(matrix(ncol=4,nrow = 0))
colnames(DTdecile)<- c("Decile","per_correct_preds","No_correct_Preds","cum_preds")
#-----Initialize variables
DTnum_of_deciles = 10
DTObs_per_decile <- nrow(DTpredicted_data)/DTnum_of_deciles
DTdecile_count = 1
DTstart = 1
DTstop = (DTstart-1) + DTObs_per_decile
DTprev_cum_pred <- 0
DTx = 0
#-----Loop through DF and create deciles
while (DTx < nrow(DTpredicted_data)) {
DTsubset <- DTpredicted_data[c(DTstart:DTstop),]
DTcorrect_count <- ifelse(DTsubset$Actual_Value == DTsubset$Predicted_Value, 1, 0)
DTno_correct_Preds <- sum(DTcorrect_count, na.rm = TRUE)
DTper_correct_Preds <- (DTno_correct_Preds / DTObs_per_decile) * 100
DTcum_preds <- DTno_correct_Preds+DTprev_cum_pred
DTaddRow <- data.frame("Decile" = DTdecile_count, "per_correct_preds" = DTper_correct_Preds, "No_correct_Preds" = DTno_correct_Preds, "cum_preds" = DTcum_preds)
DTdecile <- rbind(DTdecile,DTaddRow)
DTprev_cum_pred <- DTprev_cum_pred+DTno_correct_Preds
DTstart <- DTstop + 1
DTstop = (DTstart - 1) + DTObs_per_decile
DTx <- DTx+DTObs_per_decile
DTdecile_count <- DTdecile_count + 1
}
#------Stability plot (correct preds per decile)
plot(DTdecile$Decile,DTdecile$per_correct_preds,type = "l",xlab = "Decile",ylab = "Percentage of correct predictions",main="Stability Plot for Class 1")
write.csv(dataset,file = "whaterthenameis.csv",row.names = FALSE)
dataset <- read.csv("whaterthenameis.csv",header = TRUE)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
#options(scipen = 99999)
#Authors BH
library(rpart)
library(readr)
library(caTools)
library(dplyr)
library(party)
library(partykit)
library(rpart.plot)
library(rpart)
library(pROC)
### Step 1 - Load data and get summaries
dataset <- read.csv("framingham.csv") %>% # read in the data
mutate(TenYearCHD = factor(TenYearCHD)) # target variable dependent variable to factor
summary(dataset)
str(dataset)
### Step 2 - Split data into training and testing data
set.seed(1)
DTDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
DTtrainData <- dataset[DTDataset,]
dim(DTtrainData)
DTtestData <- dataset[!DTDataset,]
dim(DTtestData)
### Step 3 - Fit a Decision Tree using training data
#DTmodel <- rpart(TenYearCHD ~ .,method="class", data=DTtrainData, parms = list (split ="information gain"), control = rpart.control(minsplit = 10, maxdepth = 5))
#DTmodel <- rpart(TenYearCHD ~ .,method="class", data=DTtrainData, parms = list (split ="gini"), control = rpart.control(minsplit = 15, maxdepth = 5))
DTmodel <- rpart(TenYearCHD ~ .,method="class", data=DTtrainData)
# Fitting the model
#rpart.plot(DTmodel, type=3, extra = 101, fallen.leaves = F, cex = 0.8) ##try extra with 2,8,4, 101
rpart.plot(DTmodel) ##try extra with 2,8,4, 101
summary(DTmodel) # detailed summary of splits
DTmodel #prints the rules
###Step 4 - Use the fitted model to do predictions for the test data
DTpredTest <- predict(DTmodel, DTtestData, type="class")
DTprobTest <- predict(DTmodel, DTtestData, type="prob")
DTactualTest <- DTtestData$TenYearCHD
### Step 5 - Create Confusion Matrix and compute the misclassification error
DTt <- table(predictions= DTpredTest, actual = DTactualTest)
DTt # Confusion matrix
DTaccuracy <- sum(diag(DTt))/sum(DTt)
DTaccuracy
## Visualization of probabilities
hist(DTprobTest[,2], breaks = 100)
### ROC and Area Under the Curve
DTROC <- roc(DTactualTest, DTprobTest[,2])
plot(DTROC, col="blue")
DTAUC <- auc(DTROC)
DTAUC
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
DTpredicted_data <- data.frame(Probs = DTprobTest, Actual_Value= DTactualTest ,Predicted_Value = DTpredTest )  #Create data frame with prob and predictions
DTpredicted_data <- DTpredicted_data[order(DTpredicted_data$Probs.1, decreasing=TRUE),] # Sort on Probabilities
DTpredicted_data$Rank <- 1:nrow(DTpredicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=DTpredicted_data, aes(x=Rank, y=Probs.1)) +
geom_point(aes(color = DTpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of getting Cardiovascular Diseases")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
DTnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236, sysBP = 102.0, diaBP = 71, BMI = 100, heartRate = 100, glucose = 200 )
# terminal nodes
# age
# glucose
# diaBP
# BMI
DTpredProbability <-predict(DTmodel, DTnewData, type='prob')
DTpredProbability
#
## Performance measures -
#
#set.seed(1), gini
# Simplicity = 15 leaves
# Accuracy = 0.8394965 0r 0.84
# AUC = 0.6621 0r 0.66
#
#set.seed(1), information
# Simplicity = 10 leaves
# Accuracy = 0.8394965 0r 0.84
# AUC = 0.6621 0r 0.66
#
#set.seed(1), blank
# Accuracy = 0.8371361 0r 0.84
# AUC = 0.6627 0r 0.66
#
### Step 7 - EXAMINING STABILITY - Creating Decile Plots for Class 1 or 0 Sort
#
#-----Create empty df-------
DTdecile<- data.frame(matrix(ncol=4,nrow = 0))
colnames(DTdecile)<- c("Decile","per_correct_preds","No_correct_Preds","cum_preds")
#-----Initialize variables
DTnum_of_deciles = 10
DTObs_per_decile <- nrow(DTpredicted_data)/DTnum_of_deciles
DTdecile_count = 1
DTstart = 1
DTstop = (DTstart-1) + DTObs_per_decile
DTprev_cum_pred <- 0
DTx = 0
#-----Loop through DF and create deciles
while (DTx < nrow(DTpredicted_data)) {
DTsubset <- DTpredicted_data[c(DTstart:DTstop),]
DTcorrect_count <- ifelse(DTsubset$Actual_Value == DTsubset$Predicted_Value, 1, 0)
DTno_correct_Preds <- sum(DTcorrect_count, na.rm = TRUE)
DTper_correct_Preds <- (DTno_correct_Preds / DTObs_per_decile) * 100
DTcum_preds <- DTno_correct_Preds+DTprev_cum_pred
DTaddRow <- data.frame("Decile" = DTdecile_count, "per_correct_preds" = DTper_correct_Preds, "No_correct_Preds" = DTno_correct_Preds, "cum_preds" = DTcum_preds)
DTdecile <- rbind(DTdecile,DTaddRow)
DTprev_cum_pred <- DTprev_cum_pred+DTno_correct_Preds
DTstart <- DTstop + 1
DTstop = (DTstart - 1) + DTObs_per_decile
DTx <- DTx+DTObs_per_decile
DTdecile_count <- DTdecile_count + 1
}
#------Stability plot (correct preds per decile)
plot(DTdecile$Decile,DTdecile$per_correct_preds,type = "l",xlab = "Decile",ylab = "Percentage of correct predictions",main="Stability Plot for Class 1")
write.csv(dataset,file = "whaterthenameis.csv",row.names = FALSE)
dataset <- read.csv("whaterthenameis.csv",header = TRUE)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
library(caTools)
### Step 1 - Load data and get summaries
dataset <- read.csv("framingham.csv")
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
# target variable dependent variable to factor
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
## Rechecking for null values
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
dim(dataset)
head(dataset, 10)
barplot(table(dataset$TenYearCHD), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$age)
## CHD value counts
table(dataset$TenYearCHD)
### Step 2 - Split data into training and testing data
set.seed(20)
LRDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
LRtrainData <- dataset[LRDataset,]
dim(LRtrainData)
LRtestData <- dataset[!LRDataset,]
dim(LRtestData)
### Step 3 - Fit a Logistic Model using training data
#Target Variable = TenYearCHD, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
LRModel <- glm(TenYearCHD ~ ., data=LRtrainData, family=binomial(link="logit"))
summary(LRModel)
# log likelihood
logLik(LRModel)
# R-squared
LRll.null <- LRModel$null.deviance/-2
LRll.proposed <- LRModel$deviance/-2
LRr_sq <- (LRll.null - LRll.proposed)/LRll.null
LRr_sq
#P value
LRp_value <- 1 - pchisq(2*(LRll.proposed - LRll.null), df = (length(LRModel$coefficients)-1))
LRp_value
LRprobTest=predict(LRModel, LRtestData, type = "response")  # Predict probabilities
LRprobTest
LRtestData$LRprobTest <- LRpredTest
LRprobTest=predict(LRModel, LRtestData, type = "response")  # Predict probabilities
LRprobTest
LRtestData$LRprobTest <- LRpredTest
LRprobTest
#Recode probability to classification
LRpredVal <- ifelse(LRprobTest >= 0.5, 1, 0)
LRpredTest <- factor(LRpredVal, levels = c(0,1))
LRprobTest
LRpredTest
LRactualTest <-LRtestData$TenYearCHD
#LRactualTest[0:5]
LRactualTest
LRt <- table(predictions=LRpredTest, actual = LRactualTest)
LRt # Confusion matrix
hist(LRt)
LRaccuracy <- sum(diag(LRt))/sum(LRt)
LRaccuracy
### ROC and Area Under the Curve
LRROC1 <- roc(LRactualTest, LRprobTest)
plot(LRROC1, col="blue")
LRAUC1 <- auc(LRROC1)
LRAUC1
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
LRpredicted_data <- data.frame(Probs = LRprobTest, Actual_Value=LRactualTest,Predicted_Value = LRpredTest )  #Create data frame with prob and predictions
LRpredicted_data <- LRpredicted_data[order(LRpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
LRpredicted_data$Rank <- 1:nrow(LRpredicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=LRpredicted_data, aes(x=Rank, y=Probs)) +
geom_point(aes(color = LRpredicted_data$Actual_Value)) + xlab("Index") + ylab("Heart Disease Prediction")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
# male = 1, age = 1, education = 1, currentSmoker = 1, cigsPerDay = 1, BPMeds = 1, prevalentStroke = 1, prevalentHyp = 1, diabetes = 1, totChol = 1, sysBP = 1, diaBP = 1, BMI = 1, heartRate = 1, glucose = 1 TenYearCHD
#newData <- data.frame(male = 1, age = 47, cigsPerDay = 9.003089, sysBP = 102.0, glucose = 81.96675 )
#newData <- data.frame(male = 0, age = 61, cigsPerDay = 30, sysBP = 150.0, glucose = 103 )
#newData <- data.frame(male = 1, age = 47, cigsPerDay = 20, sysBP = 102.0, glucose = 66 )
newData <- data.frame(male = 1, age = 47, education = 1.97895, currentSmoker = 1, cigsPerDay = 9.003089, BPMeds = 0.02962963, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236.7216, sysBP = 102.0, diaBP = 68.0, BMI = 25.80201, heartRate = 75.87892, glucose = 81.96675 )
predProbability <-predict(LRModel, newData, type='response')
predProbability
## Performance measures
## Performance measures
# Simplicity =  coefficients
## Performance measures
# Simplicity =  coefficients
# Accuracy = 0.8528718 0r 0.85
## Performance measures
# Simplicity =  coefficients
# Accuracy = 0.8528718 0r 0.85
# AUC = 0.7071 0r 0.71
## Performance measures
# Simplicity =  coefficients
# Accuracy = 0.8528718 0r 0.85
# AUC = 0.7071 0r 0.71
## Performance measures
# Simplicity =  coefficients
# Accuracy = 0.8528718 0r 0.85
# AUC = 0.7071 0r 0.71
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
library(caTools)
### Step 1 - Load data and get summaries
dataset <- read.csv("framingham.csv")
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
## Replacing null values with the mean value
dataset[is.na(dataset$education),"education"] <- mean(dataset$education,na.rm = T)
dataset[is.na(dataset$cigsPerDay),"cigsPerDay"] <- mean(dataset$cigsPerDay, na.rm = T)
dataset[is.na(dataset$BPMeds),"BPMeds"] <- mean(dataset$BPMeds,na.rm = T)
dataset[is.na(dataset$totChol),"totChol"] <- mean(dataset$totChol,na.rm = T)
dataset[is.na(dataset$BMI),"BMI"] <- mean(dataset$BMI,na.rm = T)
dataset[is.na(dataset$heartRate),"heartRate"] <- mean(dataset$heartRate,na.rm = T)
dataset[is.na(dataset$glucose),"glucose"] <- mean(dataset$glucose,na.rm = T)
# target variable dependent variable to factor
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
## Rechecking for null values
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
dim(dataset)
head(dataset, 10)
barplot(table(dataset$TenYearCHD), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$age)
## CHD value counts
table(dataset$TenYearCHD)
### Step 2 - Split data into training and testing data
set.seed(20)
LRDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
LRtrainData <- dataset[LRDataset,]
dim(LRtrainData)
LRtestData <- dataset[!LRDataset,]
dim(LRtestData)
### Step 3 - Fit a Logistic Model using training data
#Target Variable = TenYearCHD, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
LRModel <- glm(TenYearCHD ~ ., data=LRtrainData, family=binomial(link="logit"))
summary(LRModel)
# log likelihood
logLik(LRModel)
# R-squared
LRll.null <- LRModel$null.deviance/-2
LRll.proposed <- LRModel$deviance/-2
LRr_sq <- (LRll.null - LRll.proposed)/LRll.null
LRr_sq
#P value
LRp_value <- 1 - pchisq(2*(LRll.proposed - LRll.null), df = (length(LRModel$coefficients)-1))
LRp_value
LRprobTest=predict(LRModel, LRtestData, type = "response")  # Predict probabilities
LRprobTest
#Recode probability to classification
LRpredVal <- ifelse(LRprobTest >= 0.5, 1, 0)
LRpredTest <- factor(LRpredVal, levels = c(0,1))
LRprobTest
LRpredTest
LRactualTest <-LRtestData$TenYearCHD
#LRactualTest[0:5]
LRactualTest
LRt <- table(predictions=LRpredTest, actual = LRactualTest)
LRt # Confusion matrix
hist(LRt)
LRaccuracy <- sum(diag(LRt))/sum(LRt)
LRaccuracy
### ROC and Area Under the Curve
LRROC1 <- roc(LRactualTest, LRprobTest)
plot(LRROC1, col="blue")
LRAUC1 <- auc(LRROC1)
LRAUC1
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
LRpredicted_data <- data.frame(Probs = LRprobTest, Actual_Value=LRactualTest,Predicted_Value = LRpredTest )  #Create data frame with prob and predictions
LRpredicted_data <- LRpredicted_data[order(LRpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
LRpredicted_data$Rank <- 1:nrow(LRpredicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=LRpredicted_data, aes(x=Rank, y=Probs)) +
geom_point(aes(color = LRpredicted_data$Actual_Value)) + xlab("Index") + ylab("Heart Disease Prediction")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
# male = 1, age = 1, education = 1, currentSmoker = 1, cigsPerDay = 1, BPMeds = 1, prevalentStroke = 1, prevalentHyp = 1, diabetes = 1, totChol = 1, sysBP = 1, diaBP = 1, BMI = 1, heartRate = 1, glucose = 1 TenYearCHD
#newData <- data.frame(male = 1, age = 47, cigsPerDay = 9.003089, sysBP = 102.0, glucose = 81.96675 )
#newData <- data.frame(male = 0, age = 61, cigsPerDay = 30, sysBP = 150.0, glucose = 103 )
#newData <- data.frame(male = 1, age = 47, cigsPerDay = 20, sysBP = 102.0, glucose = 66 )
newData <- data.frame(male = 1, age = 47, education = 1.97895, currentSmoker = 1, cigsPerDay = 9.003089, BPMeds = 0.02962963, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236.7216, sysBP = 102.0, diaBP = 68.0, BMI = 25.80201, heartRate = 75.87892, glucose = 81.96675 )
predProbability <-predict(LRModel, newData, type='response')
predProbability
## Performance measures
## Performance measures
# Simplicity =  coefficients
## Performance measures
# Simplicity =  coefficients
# Accuracy = 0.8528718 0r 0.85
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
# male = 1, age = 1, education = 1, currentSmoker = 1, cigsPerDay = 1, BPMeds = 1, prevalentStroke = 1, prevalentHyp = 1, diabetes = 1, totChol = 1, sysBP = 1, diaBP = 1, BMI = 1, heartRate = 1, glucose = 1 TenYearCHD
#newData <- data.frame(male = 1, age = 47, cigsPerDay = 9.003089, sysBP = 102.0, glucose = 81.96675 )
#newData <- data.frame(male = 0, age = 61, cigsPerDay = 30, sysBP = 150.0, glucose = 103 )
#newData <- data.frame(male = 1, age = 47, cigsPerDay = 20, sysBP = 102.0, glucose = 66 )
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236, sysBP = 102.0, diaBP = 71, BMI = 100, heartRate = 100, glucose = 200 )
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
#options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
library(caTools)
#library(pROC)
#library(keras)
#library(dplyr)
### Step 1 - Load data and get summaries
dataset <- read.csv("framingham.csv")
summary(dataset)
str(dataset)
#how many missing value in each ro/column
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
## Replacing null values with the mean value
dataset[is.na(dataset$education),"education"] <- mean(dataset$education,na.rm = T)
dataset[is.na(dataset$cigsPerDay),"cigsPerDay"] <- mean(dataset$cigsPerDay, na.rm = T)
dataset[is.na(dataset$BPMeds),"BPMeds"] <- mean(dataset$BPMeds,na.rm = T)
dataset[is.na(dataset$totChol),"totChol"] <- mean(dataset$totChol,na.rm = T)
dataset[is.na(dataset$BMI),"BMI"] <- mean(dataset$BMI,na.rm = T)
dataset[is.na(dataset$heartRate),"heartRate"] <- mean(dataset$heartRate,na.rm = T)
dataset[is.na(dataset$glucose),"glucose"] <- mean(dataset$glucose,na.rm = T)
#dataset$education <- NULL
#dataset$currentSmoker <- NULL
#dataset$BPMeds <- NULL
#dataset$prevalentStroke <- NULL
#dataset$prevalentHyp <- NULL
#dataset$diabetes <- NULL
#dataset$totChol <- NULL
#dataset$diaBP <- NULL
#dataset$BMI <- NULL
#dataset$heartRate <- NULL
# target variable dependent variable to factor
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
## Rechecking for null values
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
dim(dataset)
head(dataset, 10)
barplot(table(dataset$TenYearCHD), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$age)
## CHD value counts
table(dataset$TenYearCHD)
### Step 2 - Split data into training and testing data
set.seed(20)
LRDataset <-sample.split(Y=dataset$TenYearCHD, SplitRatio = 0.7)
LRtrainData <- dataset[LRDataset,]
dim(LRtrainData)
LRtestData <- dataset[!LRDataset,]
dim(LRtestData)
### Step 3 - Fit a Logistic Model using training data
#Target Variable = TenYearCHD, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
LRModel <- glm(TenYearCHD ~ ., data=LRtrainData, family=binomial(link="logit"))
summary(LRModel)
# log likelihood
logLik(LRModel)
# R-squared
LRll.null <- LRModel$null.deviance/-2
LRll.proposed <- LRModel$deviance/-2
LRr_sq <- (LRll.null - LRll.proposed)/LRll.null
LRr_sq
#P value
LRp_value <- 1 - pchisq(2*(LRll.proposed - LRll.null), df = (length(LRModel$coefficients)-1))
LRp_value
###Step 4 - Use the fitted model to do predictions for the test data
#LRprobTest- Probability for Test data, LRpredTest - Predictions for Test data, actual - Actual Value in test data
LRprobTest=predict(LRModel, LRtestData, type = "response")  # Predict probabilities
LRprobTest
#LRtestData$LRprobTest <- LRpredTest
#Recode probability to classification
LRpredVal <- ifelse(LRprobTest >= 0.5, 1, 0)
LRpredTest <- factor(LRpredVal, levels = c(0,1))
#LRprobTest [0:45]
#LRpredTest[0:45]
LRprobTest
LRpredTest
LRactualTest <-LRtestData$TenYearCHD
#LRactualTest[0:5]
LRactualTest
### Step 5 - Create Confusion Matrix and compute the misclassification error
LRt <- table(predictions=LRpredTest, actual = LRactualTest)
LRt # Confusion matrix
hist(LRt)
LRaccuracy <- sum(diag(LRt))/sum(LRt)
LRaccuracy
### ROC and Area Under the Curve
LRROC1 <- roc(LRactualTest, LRprobTest)
plot(LRROC1, col="blue")
LRAUC1 <- auc(LRROC1)
LRAUC1
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
LRpredicted_data <- data.frame(Probs = LRprobTest, Actual_Value=LRactualTest,Predicted_Value = LRpredTest )  #Create data frame with prob and predictions
LRpredicted_data <- LRpredicted_data[order(LRpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
LRpredicted_data$Rank <- 1:nrow(LRpredicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=LRpredicted_data, aes(x=Rank, y=Probs)) +
geom_point(aes(color = LRpredicted_data$Actual_Value)) + xlab("Index") + ylab("Heart Disease Prediction")
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
# male = 1, age = 1, education = 1, currentSmoker = 1, cigsPerDay = 1, BPMeds = 1, prevalentStroke = 1, prevalentHyp = 1, diabetes = 1, totChol = 1, sysBP = 1, diaBP = 1, BMI = 1, heartRate = 1, glucose = 1 TenYearCHD
#newData <- data.frame(male = 1, age = 47, cigsPerDay = 9.003089, sysBP = 102.0, glucose = 81.96675 )
#newData <- data.frame(male = 0, age = 61, cigsPerDay = 30, sysBP = 150.0, glucose = 103 )
#newData <- data.frame(male = 1, age = 47, cigsPerDay = 20, sysBP = 102.0, glucose = 66 )
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236, sysBP = 102.0, diaBP = 71, BMI = 100, heartRate = 100, glucose = 200 )
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
## Performance measures
# Simplicity =  coefficients
# Accuracy = 0.8528718 0r 0.85
# AUC = 0.7071 0r 0.71
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 30, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236, sysBP = 102.0, diaBP = 80, BMI = 50, heartRate = 100, glucose = 200 )
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 30, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 0, sysBP = 0, diaBP = 80, BMI = 50, heartRate = 100, glucose = 200 )
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 0, sysBP = 0, diaBP = 80, BMI = 50, heartRate = 100, glucose = 200 )
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 0, sysBP = 0, diaBP = 100, BMI = 50, heartRate = 100, glucose = 200 )
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 0, sysBP = 0, diaBP = 100, BMI = 100, heartRate = 100, glucose = 200 )
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 0, sysBP = 0, diaBP = 100, BMI = 100, heartRate = 150, glucose = 200 )
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
### Step 6 - Use model to make predictions on newdata. Note we can specify the newData as data.frame with one or many records
LRnewData <- data.frame(male = 0, age = 50, education = 0, currentSmoker = 0, cigsPerDay = 9, BPMeds = 0, prevalentStroke = 0, prevalentHyp = 0, diabetes = 0, totChol = 236, sysBP = 102.0, diaBP = 71, BMI = 100, heartRate = 100, glucose = 200 )
# terminal nodes
# age
# glucose
# diaBP
# BMI
predProbability <-predict(LRModel, LRnewData, type='response')
predProbability
