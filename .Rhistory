setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
#library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
dataset <- read.csv("ckd-dataset-v2.csv")
#dataset <- read.csv(file.choose())
summary(dataset)
dataset <- dataset[-c(1,2),]
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
#library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
dataset <- read.csv("ckd-dataset-v2.csv")
#dataset <- read.csv(file.choose())
summary(dataset)
dataset <- dataset[-c(1,2),]
summary(dataset)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
#library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
dataset <- read.csv("ckd-dataset-v2.csv")
#dataset <- read.csv(file.choose())
summary(dataset)
dataset <- dataset[-c(1,2),]
summary(dataset)
str(dataset)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
#library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
#dataset <- read.csv("ckd-dataset-v2.csv")
dataset <- read.csv("pizzeria_tania_data_simplified.csv")
#dataset <- read.csv(file.choose())
summary(dataset)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
#library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
dataset <- read.csv("ckd-dataset-v2.csv")
#dataset <- read.csv("pizzeria_tania_data_simplified.csv")
#dataset <- read.csv(file.choose())
summary(dataset)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
#library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
#dataset <- read.csv("ckd-dataset-v2.csv")
dataset <- read.csv("pizzeria_tania_data_simplified.csv")
#dataset <- read.csv(file.choose())
summary(dataset)
#dataset <- dataset[-c(1,2),]
#summary(dataset)
str(dataset)
View(dataset)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
#dataset <- read.csv("ckd-dataset-v2.csv")
dataset <- read.csv("pizzeria_tania_data_simplified.csv")
dataset$working_day <- as.factor(dataset$working_day)
dataset$weekend_day <- as.factor(dataset$weekend_day)
dataset$public_holiday <- as.factor(dataset$public_holiday)
#dataset <- read.csv(file.choose())
summary(dataset)
#dataset <- dataset[-c(1,2),]
#summary(dataset)
str(dataset)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
#dataset <- read.csv("ckd-dataset-v2.csv")
dataset <- read.csv("pizzeria_tania_data_simplified.csv")
str(dataset)
dataset$working_day <- as.factor(dataset$working_day)
dataset$weekend_day <- as.factor(dataset$weekend_day)
dataset$public_holiday <- as.factor(dataset$public_holiday)
#dataset <- read.csv(file.choose())
#summary(dataset)
#dataset <- dataset[-c(1,2),]
#summary(dataset)
str(dataset)
hist(dataset$weekend_day)
hist(dataset$count)
dataset$newshit <- c("now")
View(dataset)
barplot(table(DiabetesDataset$count), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$count), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$weekend_day), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$public_holiday), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$working_day), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$weekend_day), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$public_holiday), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$count)
dim(dataset)
head(dataset, 10)
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
library(caTools)
#library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
#dataset <- read.csv("ckd-dataset-v2.csv")
dataset <- read.csv("pizzeria_tania_data_simplified.csv")
str(dataset)
dataset$working_day <- as.factor(dataset$working_day)
dataset$weekend_day <- as.factor(dataset$weekend_day)
dataset$public_holiday <- as.factor(dataset$public_holiday)
#dataset <- read.csv(file.choose())
#summary(dataset)
#dataset <- dataset[-c(1,2),]
#summary(dataset)
str(dataset)
barplot(table(dataset$weekend_day), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$working_day), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$public_holiday), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$count)
dim(dataset)
head(dataset, 10)
View(dataset)
is.na(dataset)
#how many missing value in each ro/column
apply(dataset, 1,function(x) sum(is.na(x))) #number of NA per row
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
#number of row with at least one missing value
nrow(dataset[!complete.cases(ds1),])
#number of row with at least one missing value
nrow(dataset[!complete.cases(dataset),])
set.seed(20)
wrkdDataset <-sample.split(Y=dataset$working_day, SplitRatio = 0.7)
wrkdtrainData <- dataset[wrkdDataset,]
dim(wrkdtrainData)
wrkdtestData <- dataset[!wrkdDataset,]
dim(wrkdtestData)
set.seed(20)
wrkdDataset <-sample.split(Y=dataset$working_day, SplitRatio = 0.7)
wrkdtrainData <- dataset[wrkdDataset,]
dim(wrkdtrainData)
wrkdtestData <- dataset[!wrkdDataset,]
dim(wrkdtestData)
wekdDataset <-sample.split(Y=dataset$weekend_day, SplitRatio = 0.7)
wekdtrainData <- dataset[wekdDataset,]
dim(wekdtrainData)
wekdtestData <- dataset[!wekdDataset,]
dim(wekdtestData)
phdDataset <-sample.split(Y=dataset$public_holiday, SplitRatio = 0.7)
phdtrainData <- dataset[phdDataset,]
dim(phdtrainData)
wrkdtestData <- dataset[!phdDataset,]
dim(phdtestData)
set.seed(20)
wrkdDataset <-sample.split(Y=dataset$working_day, SplitRatio = 0.7)
wrkdtrainData <- dataset[wrkdDataset,]
dim(wrkdtrainData)
wrkdtestData <- dataset[!wrkdDataset,]
dim(wrkdtestData)
wekdDataset <-sample.split(Y=dataset$weekend_day, SplitRatio = 0.7)
wekdtrainData <- dataset[wekdDataset,]
dim(wekdtrainData)
wekdtestData <- dataset[!wekdDataset,]
dim(wekdtestData)
phdDataset <-sample.split(Y=dataset$public_holiday, SplitRatio = 0.7)
phdtrainData <- dataset[phdDataset,]
dim(phdtrainData)
phdtestData <- dataset[!phdDataset,]
dim(phdtestData)
wrkdrModel <- glm(Class ~ ., data=wrkdtrainData, family=binomial(link="logit"))
#Target Variable = Class, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
summary(wrkdrModel)
### Step 3 - Fit a Logistic Model using training data
wrkdrModel <- glm(Class ~ ., data=wrkdtrainData, family=binomial(link="logit"))
### Step 3 - Fit a Logistic Model using training data
wrkdrModel <- glm(working_day ~ ., data=wrkdtrainData, family=binomial(link="logit"))
#Target Variable = Class, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
summary(wrkdrModel)
wekdrModel <- glm(weekend_day ~ ., data=wekdtrainData, family=binomial(link="logit"))
#Target Variable = Class, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
summary(wekdrModel)
phdrModel <- glm(public_holiday ~ ., data=phdtrainData, family=binomial(link="logit"))
#Target Variable = Class, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
summary(phdrModel)
# log likelihood
logLik(wrkdrModel)
logLik(wekdrModel)
logLik(phdrModel)
logLik(wrkdrModel)
logLik(wekdrModel)
logLik(phdrModel)
wrkdll.null <- wrkdrModel$null.deviance/-2
wrkdll.proposed <- wrkdrModel$deviance/-2
wrkdr_sq <- (wrkdll.null - wrkdll.proposed)/wrkdll.null
wrkdr_sq
phdll.null <- phdrModel$null.deviance/-2
phdll.proposed <- phdrModel$deviance/-2
phdr_sq <- (phdll.null - phdll.proposed)/phdll.null
phdr_sq
wrkdll.null <- wrkdrModel$null.deviance/-2
wrkdll.proposed <- wrkdrModel$deviance/-2
wrkdr_sq <- (wrkdll.null - wrkdll.proposed)/wrkdll.null
wrkdr_sq
wekdll.null <- wekdrModel$null.deviance/-2
wekdll.proposed <- wekdrModel$deviance/-2
wekdr_sq <- (wekdll.null - wekdll.proposed)/wekdll.null
wekdr_sq
phdll.null <- phdrModel$null.deviance/-2
phdll.proposed <- phdrModel$deviance/-2
phdr_sq <- (phdll.null - phdll.proposed)/phdll.null
phdr_sq
wrkdll.null <- wrkdrModel$null.deviance/-2
wrkdll.proposed <- wrkdrModel$deviance/-2
wrkdr_sq <- (wrkdll.null - wrkdll.proposed)/wrkdll.null
wrkdr_sq
wekdll.null <- wekdrModel$null.deviance/-2
wekdll.proposed <- wekdrModel$deviance/-2
wekdr_sq <- (wekdll.null - wekdll.proposed)/wekdll.null
wekdr_sq
phdll.null <- phdrModel$null.deviance/-2
phdll.proposed <- phdrModel$deviance/-2
phdr_sq <- (phdll.null - phdll.proposed)/phdll.null
phdr_sq
wrkdp_value <- 1 - pchisq(2*(wrkdll.proposed - wrkdll.null), df = (length(wrkdrModel$coefficients)-1))
wrkdp_value
wekdp_value <- 1 - pchisq(2*(wekdll.proposed - wekdll.null), df = (length(wekdrModel$coefficients)-1))
wekdp_value
phdp_value <- 1 - pchisq(2*(phdll.proposed - phdll.null), df = (length(phdrModel$coefficients)-1))
phdp_value
wrkdprobTest=predict(wrkdrModel, wrkdtestData, type = "response")  # Predict probabilities
wrkdprobTest=predict(wrkdrModel, wrkdtestData, type = "response")  # Predict probabilities
wekdprobTest=predict(wekdrModel, wekdtestData, type = "response")  # Predict probabilities
phdprobTest=predict(phdrModel, phdtestData, type = "response")  # Predict probabilities
wrkdpredVal <- ifelse(wrkdprobTest >= 0.5, 1, 0)
wrkdpredTest <- factor(wrkdpredVal, levels = c(0,1))
wekdpredVal <- ifelse(wekdprobTest >= 0.5, 1, 0)
wekdpredTest <- factor(wekdpredVal, levels = c(0,1))
phdpredVal <- ifelse(phdprobTest >= 0.5, 1, 0)
phdpredTest <- factor(phdpredVal, levels = c(0,1))
wrkdactualTest <-wrkdtestData$working_day
wrkdactualTest[0:5]
wekdactualTest <-wekdtestData$weekend_day
wekdactualTest[0:5]
phdactualTest <-phdtestData$public_holiday
phdactualTest[0:5]
wrkdt <- table(predictions=wrkdpredTest, actual = wrkdactualTest)
wrkdt # Confusion matrix
wrkdaccuracy <- sum(diag(wrkdt))/sum(wrkdt)
wrkdaccuracy
wrkdt <- table(predictions=wrkdpredTest, actual = wrkdactualTest)
wrkdt # Confusion matrix
wrkdaccuracy <- sum(diag(wrkdt))/sum(wrkdt)
wrkdaccuracy
wekdt <- table(predictions=wekdpredTest, actual = wekdactualTest)
wekdt # Confusion matrix
wekdaccuracy <- sum(diag(wekdt))/sum(wekdt)
wekdaccuracy
phdt <- table(predictions=phdpredTest, actual = phdactualTest)
phdt # Confusion matrix
phdaccuracy <- sum(diag(phdt))/sum(phdt)
phdaccuracy
wrkdROC1 <- roc(wrkdactualTest, wrkdprobTest)
plot(wrkdROC1, col="blue")
wrkdAUC1 <- auc(wrkdROC1)
wrkdAUC1
library(pROC)
wrkdROC1 <- roc(wrkdactualTest, wrkdprobTest)
plot(wrkdROC1, col="blue")
wrkdAUC1 <- auc(wrkdROC1)
wrkdAUC1
phdROC1 <- roc(phdactualTest, phdprobTest)
plot(phdROC1, col="blue")
phdAUC1 <- auc(phdROC1)
phdAUC1
wekdROC1 <- roc(wekdactualTest, wekdprobTest)
plot(wekdROC1, col="blue")
wekdAUC1 <- auc(wekdROC1)
wekdAUC1
plot(wrkdROC1, col="blue")
plot(wekdROC1, col="blue")
plot(phdROC1, col="blue")
wrkdpredicted_data <- data.frame(Probs = wrkdprobTest, Actual_Value=wrkdactualTest,Predicted_Value = wrkdpredTest )  #Create data frame with prob and predictions
wrkdpredicted_data <- wrkdpredicted_data[order(wrkdpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
wrkdpredicted_data$Rank <- 1:nrow(wrkdpredicted_data) # Add a new variable rank
library(ggplot2)
ggplot(data=wrkdpredicted_data, aes(x=Rank, y=Probs)) +
geom_point(aes(color = wrkdpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of getting Diabetes")
ggplot(data=wrkdpredicted_data, aes(x=Rank, y=Probs)) +
geom_point(aes(color = wrkdpredicted_data$Actual_Value)) + xlab("Index") + ylab("Predicted Probability of getting Diabetes")
setwd("C:/Data/BujuBanton/msc/comp6115kdda/worksheets/Project1")
getwd()
rm(list = ls())
options(scipen = 99999)
#install needed libraries
#installus <- c("rpart","raprt.plot","pROC","caTools","keras")
#install.packages(installus)
library(caTools)
library(pROC)
#library(keras)
### Step 1 - Load data and get summaries
#file <pima-indians-diabetes_headings.csv>
## Choose file
#dataset <- read.csv("ckd-dataset-v2.csv")
dataset <- read.csv("pizzeria_tania_data_simplified.csv")
summary(dataset)
str(dataset)
dataset$working_day <- as.factor(dataset$working_day)
dataset$weekend_day <- as.factor(dataset$weekend_day)
dataset$public_holiday <- as.factor(dataset$public_holiday)
str(dataset)
barplot(table(dataset$weekend_day), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$working_day), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
barplot(table(dataset$public_holiday), ylab ="Frequency", main = "Distribution of Target Class", col="lightblue")
hist(dataset$count)
dim(dataset)
head(dataset, 10)
is.na(dataset)
#number of row with at least one missing value
nrow(dataset[!complete.cases(dataset),])
#how many missing value in each ro/column
apply(dataset, 1,function(x) sum(is.na(x))) #number of NA per row
apply(dataset, 2,function(x) sum(is.na(x))) #number of NA per column
### Step 2 - Split data into training and testing data
set.seed(20)
wrkdDataset <-sample.split(Y=dataset$working_day, SplitRatio = 0.7)
wrkdtrainData <- dataset[wrkdDataset,]
dim(wrkdtrainData)
wrkdtestData <- dataset[!wrkdDataset,]
dim(wrkdtestData)
wekdDataset <-sample.split(Y=dataset$weekend_day, SplitRatio = 0.7)
wekdtrainData <- dataset[wekdDataset,]
dim(wekdtrainData)
wekdtestData <- dataset[!wekdDataset,]
dim(wekdtestData)
phdDataset <-sample.split(Y=dataset$public_holiday, SplitRatio = 0.7)
phdtrainData <- dataset[phdDataset,]
dim(phdtrainData)
phdtestData <- dataset[!phdDataset,]
dim(phdtestData)
### Step 3 - Fit a Logistic Model using training data
wrkdrModel <- glm(working_day ~ ., data=wrkdtrainData, family=binomial(link="logit"))
#Target Variable = Class, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
summary(wrkdrModel)
wekdrModel <- glm(weekend_day ~ ., data=wekdtrainData, family=binomial(link="logit"))
#Target Variable = Class, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
summary(wekdrModel)
phdrModel <- glm(public_holiday ~ ., data=phdtrainData, family=binomial(link="logit"))
#Target Variable = Class, Input Vaiables = All, family = binomial (binary target variable) - Logistic regression using logit
summary(phdrModel)
# log likelihood
logLik(wrkdrModel)
logLik(wekdrModel)
logLik(phdrModel)
# R-squared
wrkdll.null <- wrkdrModel$null.deviance/-2
wrkdll.proposed <- wrkdrModel$deviance/-2
wrkdr_sq <- (wrkdll.null - wrkdll.proposed)/wrkdll.null
wrkdr_sq
wekdll.null <- wekdrModel$null.deviance/-2
wekdll.proposed <- wekdrModel$deviance/-2
wekdr_sq <- (wekdll.null - wekdll.proposed)/wekdll.null
wekdr_sq
phdll.null <- phdrModel$null.deviance/-2
phdll.proposed <- phdrModel$deviance/-2
phdr_sq <- (phdll.null - phdll.proposed)/phdll.null
phdr_sq
#P value
wrkdp_value <- 1 - pchisq(2*(wrkdll.proposed - wrkdll.null), df = (length(wrkdrModel$coefficients)-1))
wrkdp_value
wekdp_value <- 1 - pchisq(2*(wekdll.proposed - wekdll.null), df = (length(wekdrModel$coefficients)-1))
wekdp_value
phdp_value <- 1 - pchisq(2*(phdll.proposed - phdll.null), df = (length(phdrModel$coefficients)-1))
phdp_value
###Step 4 - Use the fitted model to do predictions for the test data
#probTest- Probability for Test data, predTest - Predictions for Test data, actual - Actual Value in test data
wrkdprobTest=predict(wrkdrModel, wrkdtestData, type = "response")  # Predict probabilities
wekdprobTest=predict(wekdrModel, wekdtestData, type = "response")  # Predict probabilities
phdprobTest=predict(phdrModel, phdtestData, type = "response")  # Predict probabilities
#Recode probability to classification
wrkdpredVal <- ifelse(wrkdprobTest >= 0.5, 1, 0)
wrkdpredTest <- factor(wrkdpredVal, levels = c(0,1))
wekdpredVal <- ifelse(wekdprobTest >= 0.5, 1, 0)
wekdpredTest <- factor(wekdpredVal, levels = c(0,1))
phdpredVal <- ifelse(phdprobTest >= 0.5, 1, 0)
phdpredTest <- factor(phdpredVal, levels = c(0,1))
wrkdprobTest [0:5]
wrkdpredTest[0:5]
wekdprobTest [0:5]
wekdpredTest[0:5]
phdprobTest [0:5]
phdpredTest[0:5]
wrkdactualTest <-wrkdtestData$working_day
wrkdactualTest[0:5]
wekdactualTest <-wekdtestData$weekend_day
wekdactualTest[0:5]
phdactualTest <-phdtestData$public_holiday
phdactualTest[0:5]
### Step 5 - Create Confusion Matrix and compute the misclassification error
wrkdt <- table(predictions=wrkdpredTest, actual = wrkdactualTest)
wrkdt # Confusion matrix
wrkdaccuracy <- sum(diag(wrkdt))/sum(wrkdt)
wrkdaccuracy
wekdt <- table(predictions=wekdpredTest, actual = wekdactualTest)
wekdt # Confusion matrix
wekdaccuracy <- sum(diag(wekdt))/sum(wekdt)
wekdaccuracy
phdt <- table(predictions=phdpredTest, actual = phdactualTest)
phdt # Confusion matrix
phdaccuracy <- sum(diag(phdt))/sum(phdt)
phdaccuracy
### ROC and Area Under the Curve
wrkdROC1 <- roc(wrkdactualTest, wrkdprobTest)
plot(wrkdROC1, col="blue")
wrkdAUC1 <- auc(wrkdROC1)
wrkdAUC1
wekdROC1 <- roc(wekdactualTest, wekdprobTest)
plot(wekdROC1, col="blue")
wekdAUC1 <- auc(wekdROC1)
wekdAUC1
phdROC1 <- roc(phdactualTest, phdprobTest)
plot(phdROC1, col="blue")
phdAUC1 <- auc(phdROC1)
phdAUC1
#A new dataframe with Predicted Prob, Actual Value and Predicted Value
wrkdpredicted_data <- data.frame(Probs = wrkdprobTest, Actual_Value=wrkdactualTest,Predicted_Value = wrkdpredTest )  #Create data frame with prob and predictions
wrkdpredicted_data <- wrkdpredicted_data[order(wrkdpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
wrkdpredicted_data$Rank <- 1:nrow(wrkdpredicted_data) # Add a new variable rank
wekdpredicted_data <- data.frame(Probs = wekdprobTest, Actual_Value=wekdactualTest,Predicted_Value = wekdpredTest )  #Create data frame with prob and predictions
wekdpredicted_data <- wekdpredicted_data[order(wekdpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
wekdpredicted_data$Rank <- 1:nrow(wekdpredicted_data) # Add a new variable rank
phdpredicted_data <- data.frame(Probs = phdprobTest, Actual_Value=phdactualTest,Predicted_Value = phdpredTest )  #Create data frame with prob and predictions
phdpredicted_data <- phdpredicted_data[order(phdpredicted_data$Probs, decreasing=TRUE),] # Sort on Probabilities
phdpredicted_data$Rank <- 1:nrow(phdpredicted_data) # Add a new variable rank
View(phdpredicted_data)
